{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have collected and scraped all the data from the two websites, we wil then have to clean the data based on the types of lyrics each song contains. After converting all the columns to their respective types, we wil then remove all songs that are:\n",
    "1. Instrumentals\n",
    "2. Non-english speaking songs (if they are majority non english)\n",
    "\n",
    "First, we'll import the packages we'll be using for this notebook. Then, let's load all the songs from the data csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langdetect as ld\n",
    "import langid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data Collection/data/collected/all data/data1.csv\n",
      "../Data Collection/data/collected/all data/data2.csv\n",
      "../Data Collection/data/collected/all data/data3.csv\n",
      "../Data Collection/data/collected/all data/data4.csv\n",
      "../Data Collection/data/collected/all data/data5.csv\n",
      "../Data Collection/data/collected/all data/data6.csv\n",
      "../Data Collection/data/collected/all data/data7.csv\n",
      "../Data Collection/data/collected/all data/data8.csv\n",
      "../Data Collection/data/collected/all data/data9.csv\n",
      "../Data Collection/data/collected/all data/data10.csv\n",
      "../Data Collection/data/collected/all data/data11.csv\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "for i in range(1,12):\n",
    "    FILE = '../Data Collection/data/collected/all data/data' + str(i) + '.csv'\n",
    "    print(FILE)\n",
    "    data = pd.concat([data, pd.read_csv(FILE)])\n",
    "data = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us use the detect function from langdetect to see if these example strings are written in english or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = ['this is a sentence in english',\n",
    "            'welcome to the twilight zone', \n",
    "            \"'hola' is spanish for hello\",\n",
    "            \"おはようございます\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[en:0.9999966178658325]\n",
      "[en:0.9999987822353855]\n",
      "[en:0.9999968118127358]\n",
      "[ja:0.9999999999997472]\n"
     ]
    }
   ],
   "source": [
    "for example in examples:\n",
    "    print(ld.detect_langs(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'here is some stuff'\n",
    "langid.classify(string)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DETECTION_THRESHOLD = .9999\n",
    "def get_langdetect(lyrics):\n",
    "    try:\n",
    "        detection = ld.detect_langs(lyrics)\n",
    "        for lang in detection:\n",
    "            language, prob = lang.lang, lang.prob\n",
    "            if prob > DETECTION_THRESHOLD:\n",
    "                return language\n",
    "        return 'Likely ' + detection[0].lang\n",
    "    except:\n",
    "        return 'NaN'\n",
    "    \n",
    "def get_language(lyrics):\n",
    "    ld = get_langdetect(lyrics)\n",
    "    li = langid.classify(lyrics)[0]\n",
    "    if ld == li:\n",
    "        return ld\n",
    "    else:\n",
    "        return {'langid' : li, 'langdetect' : ld}\n",
    "\n",
    "data['language'] = data['lyrics'].apply(get_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_instrumental(lyrics):\n",
    "    if len(lyrics.split(' ')) < 5 and 'instrumental' in lyrics.lower():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "data['instrumental'] = data['lyrics'].apply(is_instrumental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9617292eb96a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to clean the lyric strings and reformat all the data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only will we have to replace \"\\n\"s and \"\\r\"s, but we will need to replace words found within parenthesis, parenthesis themselves, colons, exclamation points, periods, and other signs so that when we create our corpus, the words we extract are the same(\"corn.\" should be the same as \"corn!\"). Doing so will once again require using the str.replace() function. Reference: https://stackoverflow.com/questions/14596884/remove-text-between-and-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_characters = ['%','@','&','=','?','❓','？','.','!',',','-','~',\"'\",'’','`','*','^','/','\"','{','}','_','�',';','‘','…','[',']','—','”','\\\\','“',':',\n",
    "                 '©', '£', '$', '🔥', '#', '👑', '💃🏽', '🔐', '👋🏽', '+', '\\u0024', '\\u20AC', '\\u00A3', '\\u00A5', '\\u00A2',\n",
    "                 '\\u20B9', '\\u20A8', '\\u20B1', '\\u20A9', '\\u0E3F', '\\u20AB', '\\u20AA', '\\u00A9', '\\u00AE', '\\u2117',\n",
    "                 '\\u2122', '\\u2120', '\\xad', '\\u2028', '⛽️', '✡', '《', '「', '」', '。', '￼', '🐐', '👅', '👉🏾', '👴🏼', '💇', '💋',\n",
    "                 '💪', '💸', '🔮', '😉', '😎', '😷', '🚷', '►', '„', '•', '†', '–', '‒', '«', '\\x93', '°', '¡', '¦',\n",
    "                 '♪', '\\x98', '|', '|', '½', '\\x80', '🍻', '🙏', '®', '¿', '🏁', '❤', '∞', 'â', '€˜','\\u03B1','\\u03B2','\\u03B3','\\u03B4','\\u03B5','\\u03B6','\\u03B7','\\u03B8','\\u03B9','\\u03BA','\\u03BB','\\u03BC','\\u03BD','\\u03BE','\\u03BF','\\u03C1','\\u03C3','\\u03C4','\\u03C5','\\u03C6','\\u03C7','\\u03C8','\\u03C9','\\u0391','\\u0392','\\u0393','\\u0394','\\u0395','\\u0396','\\u0397','\\u0398','\\u0399','\\u039A','\\u039B','\\u039C','\\u039D','\\u039E','\\u039F','\\u03A0','\\u03A2','\\u03A3','\\u03A4','\\u03A5','\\u03A6','\\u03A7','\\u03A8','\\u03A9',\n",
    "                 '<', '>']\n",
    "\n",
    "space_likes = ['\\xa0', '\\t', '\\u0009', '\\u000D', '\\u00A0', '\\u0020', '\\u1680', '\\u180E', '\\u2000',\n",
    "               '\\u2001', '\\u2002', '\\u2003', '\\u2004', '\\u2005', '\\u2006', '\\u2007', '\\u2008', '\\u2009',\n",
    "               '\\u200A', '\\u200B', '\\u202F', '\\u205F', '\\u3000', '\\uFEFF', '\\r']\n",
    "\n",
    "def clean_lyrics(lyrics):\n",
    "    return split_lyrics(replace_numerics(remove_extranious(remove_emoji(lyrics))))\n",
    "\n",
    "def split_lyrics(lyrics):\n",
    "    lyrics = lyrics.replace('\\u000A','\\n')\n",
    "    lines = []\n",
    "    for line in lyrics.split('\\n'):\n",
    "        if line != '':\n",
    "            lines.append(line.strip())\n",
    "    return lines\n",
    "\n",
    "def remove_extranious(lyrics):\n",
    "    lyrics = re.sub(r'(?s)\\[.*?\\]', '', lyrics)\n",
    "    lyrics = re.sub(r'(?s)\\(.*?\\)', '', lyrics)\n",
    "    lyrics = re.sub(r'(?s)\\<.*?\\>', '', lyrics)\n",
    "    for character in space_likes:\n",
    "        lyrics = lyrics.replace(character, ' ')\n",
    "    for character in bad_characters:\n",
    "        lyrics = lyrics.replace(character, '')\n",
    "    return lyrics\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def replace_numerics(lyrics):\n",
    "    lyrics = re.sub(r'[0-9]+', ' # ', lyrics)\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['lyrics'] = data['lyrics'].apply(clean_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics_length(lyrics):\n",
    "    length = 0\n",
    "    for line in lyrics:\n",
    "        length += len(line.split(' '))\n",
    "    return length\n",
    "data['song length'] = data['lyrics'].apply(get_lyrics_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_genre(genres_string):\n",
    "    genres = literal_eval(genres_string)\n",
    "    genre_list = []\n",
    "    for genre in genres:\n",
    "        genre_list.append(genre.replace('Genius','').strip().lower())\n",
    "    return genre_list\n",
    "data['genres'] = data['genres'].apply(clean_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have in total 118709 datapoints\n",
      "We have 84338 English datapoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TannerSims\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>listens</th>\n",
       "      <th>hotness</th>\n",
       "      <th>genres</th>\n",
       "      <th>genius ID</th>\n",
       "      <th>spotify ID</th>\n",
       "      <th>language</th>\n",
       "      <th>instrumental</th>\n",
       "      <th>song length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fast Cars</td>\n",
       "      <td>Craig David</td>\n",
       "      <td>[Fast cars, Fast women, Speed bikes with the n...</td>\n",
       "      <td>751624</td>\n",
       "      <td>28</td>\n",
       "      <td>[r&amp;b, rock]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watching The Rain</td>\n",
       "      <td>Scapegoat Wax</td>\n",
       "      <td>[Hello hello its me again, You know since youv...</td>\n",
       "      <td>10681</td>\n",
       "      <td>6</td>\n",
       "      <td>[pop]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Infierno</td>\n",
       "      <td>Mesita</td>\n",
       "      <td>[No sé lo que me estás haciendo, Con esa mirad...</td>\n",
       "      <td>628847</td>\n",
       "      <td>0</td>\n",
       "      <td>[uruguay, latin urban, trap, en español, latin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'langid': 'es', 'langdetect': 'Likely es'}</td>\n",
       "      <td>False</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Balaio</td>\n",
       "      <td>Itamar Assumpção</td>\n",
       "      <td>[Nega, O que que tem no balaio, O que que tem ...</td>\n",
       "      <td>16495</td>\n",
       "      <td>10</td>\n",
       "      <td>[brasil, avant garde, em português, pop]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>False</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Venganza</td>\n",
       "      <td>Ivy Queen</td>\n",
       "      <td>[coro, Ya me canse de tus cosas, Hoy quiero ba...</td>\n",
       "      <td>94916</td>\n",
       "      <td>0</td>\n",
       "      <td>[en español, pop]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>False</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title            artist  \\\n",
       "0          Fast Cars       Craig David   \n",
       "1  Watching The Rain     Scapegoat Wax   \n",
       "2           Infierno            Mesita   \n",
       "3             Balaio  Itamar Assumpção   \n",
       "4           Venganza         Ivy Queen   \n",
       "\n",
       "                                              lyrics  listens  hotness  \\\n",
       "0  [Fast cars, Fast women, Speed bikes with the n...   751624       28   \n",
       "1  [Hello hello its me again, You know since youv...    10681        6   \n",
       "2  [No sé lo que me estás haciendo, Con esa mirad...   628847        0   \n",
       "3  [Nega, O que que tem no balaio, O que que tem ...    16495       10   \n",
       "4  [coro, Ya me canse de tus cosas, Hoy quiero ba...    94916        0   \n",
       "\n",
       "                                              genres  genius ID spotify ID  \\\n",
       "0                                        [r&b, rock]        NaN        NaN   \n",
       "1                                              [pop]        NaN        NaN   \n",
       "2  [uruguay, latin urban, trap, en español, latin...        NaN        NaN   \n",
       "3           [brasil, avant garde, em português, pop]        NaN        NaN   \n",
       "4                                  [en español, pop]        NaN        NaN   \n",
       "\n",
       "                                      language  instrumental  song length  \n",
       "0                                           en         False          402  \n",
       "1                                           en         False          278  \n",
       "2  {'langid': 'es', 'langdetect': 'Likely es'}         False          430  \n",
       "3                                           pt         False          360  \n",
       "4                                           es         False          294  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('We have in total ' + str(len(data)) + ' datapoints')\n",
    "print('We have ' + str(len(data[data['instrumental'] == False][data['language'] == 'en'])) + ' English datapoints')\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks great, so lets export to csv for use in the next steps. We'll be saving both the entire dataset as well as the filtered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TannerSims\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data.to_csv('entire_clean.csv', index = False)\n",
    "data[data['instrumental'] == False][data['language'] == 'en'].to_csv('english_clean.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
